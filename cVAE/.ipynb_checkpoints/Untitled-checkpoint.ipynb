{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 64         # number of data points in each batch\n",
    "N_EPOCHS = 10           # times to run the model on complete data\n",
    "INPUT_DIM = 28 * 28     # size of each input\n",
    "HIDDEN_DIM = 256        # hidden dimension\n",
    "LATENT_DIM = 75         # latent vector dimension\n",
    "N_CLASSES = 10          # number of classes in the data\n",
    "lr = 1e-3               # learning rate\n",
    "\n",
    "transforms = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(\n",
    "    './data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms)\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    './data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms\n",
    ")\n",
    "\n",
    "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "def idx2onehot(idx, n=N_CLASSES):\n",
    "\n",
    "    assert idx.shape[1] == 1\n",
    "    assert torch.max(idx).item() < n\n",
    "\n",
    "    onehot = torch.zeros(idx.size(0), n)\n",
    "    onehot.scatter_(1, idx.data, 1)\n",
    "\n",
    "    return onehot\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    ''' This the encoder part of VAE\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, n_classes):\n",
    "        '''\n",
    "        Args:\n",
    "            input_dim: A integer indicating the size of input (in case of MNIST 28 * 28).\n",
    "            hidden_dim: A integer indicating the size of hidden dimension.\n",
    "            latent_dim: A integer indicating the latent size.\n",
    "            n_classes: A integer indicating the number of classes. (dimension of one-hot representation of labels)\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(input_dim + n_classes, hidden_dim)\n",
    "        self.mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.var = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, input_dim + n_classes]\n",
    "\n",
    "        hidden = F.relu(self.linear(x))\n",
    "        # hidden is of shape [batch_size, hidden_dim]\n",
    "\n",
    "        # latent parameters\n",
    "        mean = self.mu(hidden)\n",
    "        # mean is of shape [batch_size, latent_dim]\n",
    "        log_var = self.var(hidden)\n",
    "        # log_var is of shape [batch_size, latent_dim]\n",
    "\n",
    "        return mean, log_var\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    ''' This the decoder part of VAE\n",
    "    '''\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim, n_classes):\n",
    "        '''\n",
    "        Args:\n",
    "            latent_dim: A integer indicating the latent size.\n",
    "            hidden_dim: A integer indicating the size of hidden dimension.\n",
    "            output_dim: A integer indicating the size of output (in case of MNIST 28 * 28).\n",
    "            n_classes: A integer indicating the number of classes. (dimension of one-hot representation of labels)\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.latent_to_hidden = nn.Linear(latent_dim + n_classes, hidden_dim)\n",
    "        self.hidden_to_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, latent_dim + num_classes]\n",
    "        x = F.relu(self.latent_to_hidden(x))\n",
    "        # x is of shape [batch_size, hidden_dim]\n",
    "        generated_x = F.sigmoid(self.hidden_to_out(x))\n",
    "        # x is of shape [batch_size, output_dim]\n",
    "\n",
    "        return generated_x\n",
    "\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    ''' This the VAE, which takes a encoder and decoder.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, n_classes):\n",
    "        '''\n",
    "        Args:\n",
    "            input_dim: A integer indicating the size of input (in case of MNIST 28 * 28).\n",
    "            hidden_dim: A integer indicating the size of hidden dimension.\n",
    "            latent_dim: A integer indicating the latent size.\n",
    "            n_classes: A integer indicating the number of classes. (dimension of one-hot representation of labels)\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, latent_dim, n_classes)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim, input_dim, n_classes)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "\n",
    "        # encode\n",
    "        z_mu, z_var = self.encoder(x)\n",
    "\n",
    "        # sample from the distribution having latent parameters z_mu, z_var\n",
    "        # reparameterize\n",
    "        std = torch.exp(z_var / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "        x_sample = eps.mul(std).add_(z_mu)\n",
    "\n",
    "        z = torch.cat((x_sample, y), dim=1)\n",
    "\n",
    "        # decode\n",
    "        generated_x = self.decoder(z)\n",
    "\n",
    "        return generated_x, z_mu, z_var\n",
    "\n",
    "\n",
    "def calculate_loss(x, reconstructed_x, mean, log_var):\n",
    "    # reconstruction loss\n",
    "    RCL = F.binary_cross_entropy(reconstructed_x, x, size_average=False)\n",
    "    # kl divergence loss\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "    return RCL + KLD\n",
    "\n",
    "model = CVAE(INPUT_DIM, HIDDEN_DIM, LATENT_DIM, N_CLASSES)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "def train():\n",
    "    # set the train mode\n",
    "    model.train()\n",
    "\n",
    "    # loss of the epoch\n",
    "    train_loss = 0\n",
    "\n",
    "    for i, (x, y) in enumerate(train_iterator):\n",
    "        # reshape the data into [batch_size, 784]\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = x.to(device)\n",
    "\n",
    "        # convert y into one-hot encoding\n",
    "        y = idx2onehot(y.view(-1, 1))\n",
    "        y = y.to(device)\n",
    "\n",
    "        # update the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        reconstructed_x, z_mu, z_var = model(x, y)\n",
    "\n",
    "        # loss\n",
    "        loss = calculate_loss(x, reconstructed_x, z_mu, z_var)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def test():\n",
    "    # set the evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # test loss for the data\n",
    "    test_loss = 0\n",
    "\n",
    "    # we don't need to track the gradients, since we are not updating the parameters during evaluation / testing\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(test_iterator):\n",
    "            # reshape the data\n",
    "            x = x.view(-1, 28 * 28)\n",
    "            x = x.to(device)\n",
    "\n",
    "            # convert y into one-hot encoding\n",
    "            y = idx2onehot(y.view(-1, 1))\n",
    "            y = y.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            reconstructed_x, z_mu, z_var = model(x, y)\n",
    "\n",
    "            # loss\n",
    "            loss = calculate_loss(x, reconstructed_x, z_mu, z_var)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    return test_loss\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "for e in range(N_EPOCHS):\n",
    "\n",
    "    train_loss = train()\n",
    "    test_loss = test()\n",
    "\n",
    "    train_loss /= len(train_dataset)\n",
    "    test_loss /= len(test_dataset)\n",
    "\n",
    "    print(f'Epoch {e}, Train Loss: {train_loss:.2f}, Test Loss: {test_loss:.2f}')\n",
    "\n",
    "    if best_test_loss > test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        patience_counter = 1\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter > 3:\n",
    "        break\n",
    "\n",
    "# create a random latent vector\n",
    "z = torch.randn(1, LATENT_DIM).to(device)\n",
    "\n",
    "# pick randomly 1 class, for which we want to generate the data\n",
    "y = torch.randint(0, N_CLASSES, (1, 1)).to(dtype=torch.long)\n",
    "print(f'Generating a {y.item()}')\n",
    "\n",
    "y = idx2onehot(y).to(device, dtype=z.dtype)\n",
    "z = torch.cat((z, y), dim=1)\n",
    "\n",
    "reconstructed_img = model.decoder(z)\n",
    "img = reconstructed_img.view(28, 28).data\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
